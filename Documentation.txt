Overall Design of Tokenizer:


The tokenizer includes three java files: Tokenizer, Main, and Token. Main serves as an iteration script and initializes a map, the alphabet to store all valid keywords and special characters as keys with their corresponding codes as their values. All valid alphabet elements are added in the addWords() method. This is done to make the type checking easier and pull the corresponding code in a simple manner. Main initializes the Tokenizer object and iterates until the currentToken() returns a null, which indicates an end-of-file. 


The token is grabbed from the Tokenizer’s currentToken() method and is classified as either number, identifier or keyword in the iteration loop. An informative error message is printed if the Token is erroneous with the token’s line number. Afterwards, the iteration calls the nextToken() method to advance to the next token in the Tokenizer object and this process is repeated until the currentToken() returns a null. I chose the main design to balance the workload between the Main and the Tokenizer. The Main does error checking and prints the codes, while the Tokenizer tokenizes each line and returns the next token as it is called. This design reduced the code complexity and allowed me to keep both files around 120 lines of code.


Tokenizer serves as a token provider and its constructor takes an opened input file to pass it to a global variable as it initializes other necessary global variables, such as line, linenumber, token, and tokens list. The nextToken() reads a line from the input file and puts the line into tokenize() that adds a space before and after all special characters using regular expressions. This is so that I can simply split the line using spaces. 


The line is then put into a split function to separate all tokens by spaces, and the tokens are put into tokens list. This approach simplified the tokenization process significantly. This process is repeated once the list is empty or the line is blank. So that the blank lines are automatically skipped and the tokens list can provide new tokens until the file ends. The nextToken() removes the first element from the tokens list and sets it to the current token.


Token file is a data structure that contains the string value of the token and the line where it exist. It is mainly used to keep multiple values of the token, such as its line number.


Overall Design of Parser:


Overall the parser is built using the node representation of the parse tree. A class was created for each non-terminal symbol that has a parse and a print method. The root non-terminal symbol, the program, is the starting point that triggers all other nodes to parse their child nodes,  and it is the only public class for the parser. 


The client from Main.java would initialize an empty programNode object using its constructor that initialized its child nodes. The client would then call parseProgram(Tokenizer t) and pass the tokenizer of the CORE program that will be parsed. The parseProgram(Tokenizer t) would parse the program node that has all the appropriate children.


The parseProgram(Tokenizer t) would trigger all the other nodes to get parsed using the Tokenizer. The tokenizer would be passed around all the child nodes, and the sub trees of the program node would get parsed as the tokens are proceeded. The parseProgram(Tokenizer t) would initiate chain calls to all the other nodes using the tokenizer, and each child will have their own subtrees.


Once the program is fully parsed, the parsed programNode has a method called printProgram() that will start printing the parsed program with correct terminals and indentation. printProgram() would trigger all the child nodes to print their subtrees. Therefore, the entire parsed tree of the core program would be printed with a chain call that is similar to the parsing.


Overall Design of Executor:


The execProgram in the program node starts the execution of the whole program with execStmtSeq method only. Declarations, such as DeclNode, and DeclSeqNode are not executed as declarations are already binded during parsing. The execProgram triggers it to execute only one statement sequence, and the StmtSeqNode triggers all other required nodes based on the parse tree based on node representation.


The only modification to the parser aside from a couple of utility functions, such as isInitialized in IdNode, is that the execXXX methods were added to the statement nodes, and not the declaration nodes. The statement nodes perform the necessary operations to complete the task. Special nodes, such as InNode and OutNode interact with the user by taking in input and printing values to the console.


The Core Interpreter accepts negative numbers from the user during execution time, although it is not allowed in the parser. The Interpreter makes sure that the numbers in memory do not exceed the integer range during integer operations as well. The only issue with the statement nodes is that the InNode uses Scanner to read input from the user, and never closes the Scanner. This is because, once System.in is closed, it can never be opened again according to StackOverflow.


The Interpreter makes sure the input from the user meets the requirements of an integer, a value is initialized before it's used, and a mathematical operation is in range. These measurements were added to protect the program's integrity when calculating numbers. 
